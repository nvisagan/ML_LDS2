{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DS7_lesson_applied_modeling_2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nvisagan/DS-Unit-2-Applied-Modeling/blob/master/module2/lesson_applied_modeling_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2ha9OWxf0jw",
        "colab_type": "text"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 2, Sprint 3, Module 2*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-hTictxWYih7"
      },
      "source": [
        "# Applied Modeling, Module 2\n",
        "\n",
        "- Get **permutation importances** for model interpretation and feature selection\n",
        "- Use xgboost for **gradient boosting**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LoxNYFBXYih9"
      },
      "source": [
        "### Default Feature Importances are fast, but Permutation Importances may be more accurate\n",
        "\n",
        "- Permutation Importances\n",
        "  - [Kaggle / Dan Becker: Machine Learning Explainability](https://www.kaggle.com/dansbecker/permutation-importance)\n",
        "  - [Christoph Molnar: Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/feature-importance.html)\n",
        "- (Default) Feature Importances\n",
        "  - [Ando Saabas: Selecting good features, Part 3, Random Forests](https://blog.datadive.net/selecting-good-features-part-iii-random-forests/)\n",
        "  - [Terence Parr, et al: Beware Default Random Forest Importances](https://explained.ai/rf-importance/index.html)\n",
        "\n",
        "### Try Tree Ensembles when you do machine learning with labeled, tabular data\n",
        "- \"Tree Ensembles\" means Random Forest or **Gradient Boosting** models. \n",
        "- [Tree Ensembles often have the best predictive accuracy](https://arxiv.org/abs/1708.05070) with labeled, tabular data.\n",
        "- Why? Because trees can fit non-linear, non-[monotonic](https://en.wikipedia.org/wiki/Monotonic_function) relationships, and [interactions](https://christophm.github.io/interpretable-ml-book/interaction.html) between features.\n",
        "- A single decision tree, grown to unlimited depth, will [overfit](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/). We solve this problem by ensembling trees, with bagging (Random Forest) or **[boosting](https://www.youtube.com/watch?v=GM3CDQfQ4sw)** (Gradient Boosting).\n",
        "- Random Forest's advantage: may be less sensitive to hyperparameters. **Gradient Boosting's advantage:** may get better predictive accuracy.\n",
        "\n",
        "#### Python libraries for Gradient Boosting\n",
        "- [scikit-learn Gradient Tree Boosting](https://scikit-learn.org/stable/modules/ensemble.html#gradient-boosting) — slower than other libraries, but [the new version may be better](https://twitter.com/amuellerml/status/1129443826945396737)\n",
        "  - Anaconda: already installed\n",
        "  - Google Colab: already installed\n",
        "- [xgboost](https://xgboost.readthedocs.io/en/latest/) — can accept missing values and enforce [monotonic constraints](https://xiaoxiaowang87.github.io/monotonicity_constraint/)\n",
        "  - Anaconda, Mac/Linux: `conda install -c conda-forge xgboost`\n",
        "  - Windows: `conda install -c anaconda py-xgboost`\n",
        "  - Google Colab: already installed\n",
        "- [LightGBM](https://lightgbm.readthedocs.io/en/latest/) — can accept missing values and enforce [monotonic constraints](https://blog.datadive.net/monotonicity-constraints-in-machine-learning/)\n",
        "  - Anaconda: `conda install -c conda-forge lightgbm`\n",
        "  - Google Colab: already installed\n",
        "- [CatBoost](https://catboost.ai/) — can accept missing values and use [categorical features](https://catboost.ai/docs/concepts/algorithm-main-stages_cat-to-numberic.html) without preprocessing\n",
        "  - Anaconda: `conda install -c conda-forge catboost`\n",
        "  - Google Colab: `pip install catboost`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMejJg0w8v76",
        "colab_type": "text"
      },
      "source": [
        "### Setup\n",
        "\n",
        "You can work locally (follow the [local setup instructions](https://lambdaschool.github.io/ds/unit2/local/)) or on Colab (run the code cell below)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BFQMky3CYih-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "82bda9c2-a4aa-4ea6-a119-aee783e75063"
      },
      "source": [
        "import os, sys\n",
        "in_colab = 'google.colab' in sys.modules\n",
        "\n",
        "# If you're in Colab...\n",
        "if in_colab:\n",
        "    # Pull files from Github repo\n",
        "    os.chdir('/content')\n",
        "    !git init .\n",
        "    !git remote add origin https://github.com/LambdaSchool/DS-Unit-2-Applied-Modeling.git\n",
        "    !git pull origin master\n",
        "    \n",
        "    # Install required python packages\n",
        "    !pip install -r requirements.txt\n",
        "    \n",
        "    # Change into directory for module\n",
        "    os.chdir('module2')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initialized empty Git repository in /content/.git/\n",
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 68 (delta 0), reused 4 (delta 0), pack-reused 63\u001b[K\n",
            "Unpacking objects: 100% (68/68), done.\n",
            "From https://github.com/LambdaSchool/DS-Unit-2-Applied-Modeling\n",
            " * branch            master     -> FETCH_HEAD\n",
            " * [new branch]      master     -> origin/master\n",
            "Checking out files: 100% (27/27), done.\n",
            "Collecting category_encoders==2.0.0 (from -r requirements.txt (line 1))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/a1/f7a22f144f33be78afeb06bfa78478e8284a64263a3c09b1ef54e673841e/category_encoders-2.0.0-py2.py3-none-any.whl (87kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 10.6MB/s \n",
            "\u001b[?25hCollecting eli5==0.10.1 (from -r requirements.txt (line 2))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/2f/c85c7d8f8548e460829971785347e14e45fa5c6617da374711dec8cb38cc/eli5-0.10.1-py2.py3-none-any.whl (105kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 31.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib!=3.1.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (3.0.3)\n",
            "Collecting pandas-profiling==2.3.0 (from -r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/2f/aae19e2173c10a9bb7fee5f5cad35dbe53a393960fc91abc477dcc4661e8/pandas-profiling-2.3.0.tar.gz (127kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 62.4MB/s \n",
            "\u001b[?25hCollecting pdpbox==0.2.0 (from -r requirements.txt (line 5))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/23/ac7da5ba1c6c03a87c412e7e7b6e91a10d6ecf4474906c3e736f93940d49/PDPbox-0.2.0.tar.gz (57.7MB)\n",
            "\u001b[K     |████████████████████████████████| 57.7MB 1.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: plotly==4.1.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (4.1.1)\n",
            "Requirement already satisfied: seaborn==0.9.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (0.9.0)\n",
            "Requirement already satisfied: scikit-learn==0.21.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (0.21.3)\n",
            "Collecting shap==0.30.0 (from -r requirements.txt (line 9))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/98/16829410426bdd08b836c30e164c56646d6a102afb9eadd81a6bd3a8bb65/shap-0.30.0.tar.gz (240kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 48.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: xgboost==0.90 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 10)) (0.90)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.0.0->-r requirements.txt (line 1)) (0.24.2)\n",
            "Requirement already satisfied: statsmodels>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.0.0->-r requirements.txt (line 1)) (0.10.1)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.0.0->-r requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.0.0->-r requirements.txt (line 1)) (1.16.5)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.0.0->-r requirements.txt (line 1)) (0.5.1)\n",
            "Requirement already satisfied: attrs>16.0.0 in /usr/local/lib/python3.6/dist-packages (from eli5==0.10.1->-r requirements.txt (line 2)) (19.1.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from eli5==0.10.1->-r requirements.txt (line 2)) (0.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from eli5==0.10.1->-r requirements.txt (line 2)) (2.10.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from eli5==0.10.1->-r requirements.txt (line 2)) (1.12.0)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from eli5==0.10.1->-r requirements.txt (line 2)) (0.8.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.1.1->-r requirements.txt (line 3)) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.1.1->-r requirements.txt (line 3)) (2.5.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.1.1->-r requirements.txt (line 3)) (2.4.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.1.1->-r requirements.txt (line 3)) (1.1.0)\n",
            "Requirement already satisfied: missingno>=0.4.2 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.4.2)\n",
            "Collecting htmlmin>=0.1.12 (from pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "  Downloading https://files.pythonhosted.org/packages/b3/e7/fcd59e12169de19f0131ff2812077f964c6b960e7c09804d30a7bf2ab461/htmlmin-0.1.12.tar.gz\n",
            "Collecting phik>=0.9.8 (from pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/ad/24a16fa4ba612fb96a3c4bb115a5b9741483f53b66d3d3afd987f20fa227/phik-0.9.8-py3-none-any.whl (606kB)\n",
            "\u001b[K     |████████████████████████████████| 614kB 44.9MB/s \n",
            "\u001b[?25hCollecting confuse>=1.0.0 (from pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "  Downloading https://files.pythonhosted.org/packages/4c/6f/90e860cba937c174d8b3775729ccc6377eb91f52ad4eeb008e7252a3646d/confuse-1.0.0.tar.gz\n",
            "Requirement already satisfied: astropy in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.3.0->-r requirements.txt (line 4)) (3.0.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from pdpbox==0.2.0->-r requirements.txt (line 5)) (0.13.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from pdpbox==0.2.0->-r requirements.txt (line 5)) (5.4.8)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly==4.1.1->-r requirements.txt (line 6)) (1.3.3)\n",
            "Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.6/dist-packages (from shap==0.30.0->-r requirements.txt (line 9)) (4.28.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from shap==0.30.0->-r requirements.txt (line 9)) (5.5.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from shap==0.30.0->-r requirements.txt (line 9)) (0.15.0)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders==2.0.0->-r requirements.txt (line 1)) (2018.9)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->eli5==0.10.1->-r requirements.txt (line 2)) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.1.1->-r requirements.txt (line 3)) (41.2.0)\n",
            "Requirement already satisfied: nbconvert>=5.3.1 in /usr/local/lib/python3.6/dist-packages (from phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (5.6.0)\n",
            "Collecting pytest>=4.0.2 (from phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2f/19/d5f71752f71451ccc5ed5f6739e9da4a235f38783fdaf3629cae41b2ca7b/pytest-5.1.2-py3-none-any.whl (224kB)\n",
            "\u001b[K     |████████████████████████████████| 225kB 41.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: jupyter-client>=5.2.3 in /usr/local/lib/python3.6/dist-packages (from phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (5.3.1)\n",
            "Collecting pytest-pylint>=0.13.0 (from phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "  Downloading https://files.pythonhosted.org/packages/64/dc/6f35f114844fb12e38d60c4f3d2441a55baff7043ad4e013777dff55746c/pytest_pylint-0.14.1-py3-none-any.whl\n",
            "Requirement already satisfied: numba>=0.38.1 in /usr/local/lib/python3.6/dist-packages (from phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.40.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from confuse>=1.0.0->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (3.13)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.30.0->-r requirements.txt (line 9)) (4.4.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.30.0->-r requirements.txt (line 9)) (2.1.3)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.30.0->-r requirements.txt (line 9)) (4.7.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.30.0->-r requirements.txt (line 9)) (1.0.16)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.30.0->-r requirements.txt (line 9)) (0.8.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.30.0->-r requirements.txt (line 9)) (4.3.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.30.0->-r requirements.txt (line 9)) (0.7.5)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->shap==0.30.0->-r requirements.txt (line 9)) (2.3)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->shap==0.30.0->-r requirements.txt (line 9)) (4.3.0)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->shap==0.30.0->-r requirements.txt (line 9)) (1.0.3)\n",
            "Requirement already satisfied: imageio>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image->shap==0.30.0->-r requirements.txt (line 9)) (2.4.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.8.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.6.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (4.5.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (1.4.2)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (3.1.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.4.2)\n",
            "Requirement already satisfied: nbformat>=4.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (4.4.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.1.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (19.1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (1.8.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (7.2.0)\n",
            "Collecting pluggy<1.0,>=0.12 (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "  Downloading https://files.pythonhosted.org/packages/92/c7/48439f7d5fd6bddb4c04b850bb862b42e3e2b98570040dfaf68aedd8114b/pluggy-0.13.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.20)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=5.2.3->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (17.0.0)\n",
            "Requirement already satisfied: tornado>=4.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=5.2.3->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (4.5.3)\n",
            "Collecting pylint>=1.4.5 (from pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/c2/b3f73f4ac008bef6e75bca4992f3963b3f85942e0277237721ef1c151f0d/pylint-2.3.1-py3-none-any.whl (765kB)\n",
            "\u001b[K     |████████████████████████████████| 768kB 56.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: llvmlite>=0.25.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.29.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->shap==0.30.0->-r requirements.txt (line 9)) (0.6.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->shap==0.30.0->-r requirements.txt (line 9)) (0.2.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.3.0->scikit-image->shap==0.30.0->-r requirements.txt (line 9)) (0.46)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.5.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4->nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (2.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.6.0)\n",
            "Collecting mccabe<0.7,>=0.6 (from pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "  Downloading https://files.pythonhosted.org/packages/87/89/479dc97e18549e21354893e4ee4ef36db1d237534982482c3681ee6e7b57/mccabe-0.6.1-py2.py3-none-any.whl\n",
            "Collecting isort<5,>=4.2.5 (from pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/b0/c121fd1fa3419ea9bfd55c7f9c4fedfec5143208d8c7ad3ce3db6c623c21/isort-4.3.21-py2.py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 26.6MB/s \n",
            "\u001b[?25hCollecting astroid<3,>=2.2.0 (from pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/ad/7221a62a2dbce5c3b8c57fd18e1052c7331adc19b3f27f1561aa6e620db2/astroid-2.2.5-py3-none-any.whl (193kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 46.2MB/s \n",
            "\u001b[?25hCollecting typed-ast>=1.3.0; implementation_name == \"cpython\" (from astroid<3,>=2.2.0->pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/d3/9d1802c161626d0278bafb1ffb32f76b9d01e123881bbf9d91e8ccf28e18/typed_ast-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (736kB)\n",
            "\u001b[K     |████████████████████████████████| 737kB 55.4MB/s \n",
            "\u001b[?25hCollecting lazy-object-proxy (from astroid<3,>=2.2.0->pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/26/534a6d32572a9dbca11619321535c0a7ab34688545d9d67c2c204b9e3a3d/lazy_object_proxy-1.4.2-cp36-cp36m-manylinux1_x86_64.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 20.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from astroid<3,>=2.2.0->pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (1.11.2)\n",
            "Building wheels for collected packages: pandas-profiling, pdpbox, shap, htmlmin, confuse\n",
            "  Building wheel for pandas-profiling (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pandas-profiling: filename=pandas_profiling-2.3.0-py2.py3-none-any.whl size=145035 sha256=3b305fefdd224bc86a07ccb19ec62390613b3c5079eabc17f2a735e9d58aad10\n",
            "  Stored in directory: /root/.cache/pip/wheels/ce/c7/f1/dbfef4848ebb048cb1d4a22d1ed0c62d8ff2523747235e19fe\n",
            "  Building wheel for pdpbox (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pdpbox: filename=PDPbox-0.2.0-cp36-none-any.whl size=57690723 sha256=a0de78bc5e9b230440b4bc34d3b43ee5b9929be577fc3ba34c7c5f67e7d8861e\n",
            "  Stored in directory: /root/.cache/pip/wheels/7d/08/51/63fd122b04a2c87d780464eeffb94867c75bd96a64d500a3fe\n",
            "  Building wheel for shap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for shap: filename=shap-0.30.0-cp36-cp36m-linux_x86_64.whl size=356743 sha256=a49f8a0a713e1e59866dc6da8ecdfd8daf62e20abba618c6d0460a607db4c93d\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/7a/5b/34feab81170fb8bf642a7536b5127e54e00bce373564435808\n",
            "  Building wheel for htmlmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for htmlmin: filename=htmlmin-0.1.12-cp36-none-any.whl size=27084 sha256=edecd05a0ff2e24d027bad9e1a99e7ffcaddbdc17699bfa3b083e4a2334ece0d\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/07/ac/7c5a9d708d65247ac1f94066cf1db075540b85716c30255459\n",
            "  Building wheel for confuse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for confuse: filename=confuse-1.0.0-cp36-none-any.whl size=17486 sha256=e2155977219bdfa854c9c56af35887b2cc6eeff500310b0b37c50f22ee9ade00\n",
            "  Stored in directory: /root/.cache/pip/wheels/b0/b2/96/2074eee7dbf7b7df69d004c9b6ac4e32dad04fb7666cf943bd\n",
            "Successfully built pandas-profiling pdpbox shap htmlmin confuse\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: category-encoders, eli5, htmlmin, pluggy, pytest, mccabe, isort, typed-ast, lazy-object-proxy, astroid, pylint, pytest-pylint, phik, confuse, pandas-profiling, pdpbox, shap\n",
            "  Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "  Found existing installation: pandas-profiling 1.4.1\n",
            "    Uninstalling pandas-profiling-1.4.1:\n",
            "      Successfully uninstalled pandas-profiling-1.4.1\n",
            "Successfully installed astroid-2.2.5 category-encoders-2.0.0 confuse-1.0.0 eli5-0.10.1 htmlmin-0.1.12 isort-4.3.21 lazy-object-proxy-1.4.2 mccabe-0.6.1 pandas-profiling-2.3.0 pdpbox-0.2.0 phik-0.9.8 pluggy-0.13.0 pylint-2.3.1 pytest-5.1.2 pytest-pylint-0.14.1 shap-0.30.0 typed-ast-1.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-TExplb_Slf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Merge train_features.csv & train_labels.csv\n",
        "train = pd.merge(pd.read_csv('../data/tanzania/train_features.csv'), \n",
        "                 pd.read_csv('../data/tanzania/train_labels.csv'))\n",
        "\n",
        "# Read test_features.csv & sample_submission.csv\n",
        "test = pd.read_csv('../data/tanzania/test_features.csv')\n",
        "sample_submission = pd.read_csv('../data/tanzania/sample_submission.csv')\n",
        "\n",
        "\n",
        "# Split train into train & val\n",
        "train, val = train_test_split(train, train_size=0.80, test_size=0.20, \n",
        "                              stratify=train['status_group'], random_state=42)\n",
        "\n",
        "\n",
        "def wrangle(X):\n",
        "    \"\"\"Wrangle train, validate, and test sets in the same way\"\"\"\n",
        "    \n",
        "    # Prevent SettingWithCopyWarning\n",
        "    X = X.copy()\n",
        "    \n",
        "    # About 3% of the time, latitude has small values near zero,\n",
        "    # outside Tanzania, so we'll treat these values like zero.\n",
        "    X['latitude'] = X['latitude'].replace(-2e-08, 0)\n",
        "    \n",
        "    # When columns have zeros and shouldn't, they are like null values.\n",
        "    # So we will replace the zeros with nulls, and impute missing values later.\n",
        "    # Also create a \"missing indicator\" column, because the fact that\n",
        "    # values are missing may be a predictive signal.\n",
        "    cols_with_zeros = ['longitude', 'latitude', 'construction_year', \n",
        "                       'gps_height', 'population']\n",
        "    for col in cols_with_zeros:\n",
        "        X[col] = X[col].replace(0, np.nan)\n",
        "        X[col+'_MISSING'] = X[col].isnull()\n",
        "            \n",
        "    # Drop duplicate columns\n",
        "    duplicates = ['quantity_group', 'payment_type']\n",
        "    X = X.drop(columns=duplicates)\n",
        "    \n",
        "    # Drop recorded_by (never varies) and id (always varies, random)\n",
        "    unusable_variance = ['recorded_by', 'id']\n",
        "    X = X.drop(columns=unusable_variance)\n",
        "    \n",
        "    # Convert date_recorded to datetime\n",
        "    X['date_recorded'] = pd.to_datetime(X['date_recorded'], infer_datetime_format=True)\n",
        "    \n",
        "    # Extract components from date_recorded, then drop the original column\n",
        "    X['year_recorded'] = X['date_recorded'].dt.year\n",
        "    X['month_recorded'] = X['date_recorded'].dt.month\n",
        "    X['day_recorded'] = X['date_recorded'].dt.day\n",
        "    X = X.drop(columns='date_recorded')\n",
        "    \n",
        "    # Engineer feature: how many years from construction_year to date_recorded\n",
        "    X['years'] = X['year_recorded'] - X['construction_year']\n",
        "    X['years_MISSING'] = X['years'].isnull()\n",
        "    \n",
        "    # return the wrangled dataframe\n",
        "    return X\n",
        "\n",
        "train = wrangle(train)\n",
        "val = wrangle(val)\n",
        "test = wrangle(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhg8PQKt_jzP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Arrange data into X features matrix and y target vector\n",
        "target = 'status_group'\n",
        "X_train = train.drop(columns=target)\n",
        "y_train = train[target]\n",
        "X_val = val.drop(columns=target)\n",
        "y_val = val[target]\n",
        "X_test = test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8lB4z5l_eml",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "42decb45-b309-4d78-dccb-ab816b70dfcc"
      },
      "source": [
        "import category_encoders as ce\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "\n",
        "# Fit on train, score on val\n",
        "pipeline.fit(X_train, y_train)\n",
        "print('Validation Accuracy', pipeline.score(X_val, y_val))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.8135521885521886\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7HOayKBOYiit"
      },
      "source": [
        "# 3 types of feature importances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4bRhsxENYiiu"
      },
      "source": [
        "## 1. (Default) Feature Importances\n",
        "\n",
        "Fastest, good for first estimates, but be aware:\n",
        "\n",
        "\n",
        "\n",
        ">**When the dataset has two (or more) correlated features, then from the point of view of the model, any of these correlated features can be used as the predictor, with no concrete preference of one over the others.** But once one of them is used, the importance of others is significantly reduced since effectively the impurity they can remove is already removed by the first feature. As a consequence, they will have a lower reported importance. This is not an issue when we want to use feature selection to reduce overfitting, since it makes sense to remove features that are mostly duplicated by other features. But when interpreting the data, it can lead to the incorrect conclusion that one of the variables is a strong predictor while the others in the same group are unimportant, while actually they are very close in terms of their relationship with the response variable. — [Selecting good features – Part III: random forests](https://blog.datadive.net/selecting-good-features-part-iii-random-forests/) \n",
        "\n",
        "\n",
        " \n",
        " > **The scikit-learn Random Forest feature importance ... tends to inflate the importance of continuous or high-cardinality categorical variables.** ... Breiman and Cutler, the inventors of Random Forests, indicate that this method of “adding up the gini decreases for each individual variable over all trees in the forest gives a **fast** variable importance that is often very consistent with the permutation importance measure.” —  [Beware Default Random Forest Importances](https://explained.ai/rf-importance/index.html)\n",
        "\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BNVm6f7mYiiu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "184c325f-6d50-4924-875d-c49dc07eb8da"
      },
      "source": [
        "# Get feature importances\n",
        "rf = pipeline.named_steps['randomforestclassifier']\n",
        "importances = pd.Series(rf.feature_importances_, X_train.columns)\n",
        "\n",
        "# Plot feature importances\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n = 20\n",
        "plt.figure(figsize=(10,n/2))\n",
        "plt.title(f'Top {n} features')\n",
        "importances.sort_values()[-n:].plot.barh(color='grey');"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAArkAAAJOCAYAAACzyR8VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n99A0istCZwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y8HzLcCBYiiv"
      },
      "source": [
        "## 2. Drop-Column Importance\n",
        "\n",
        "The best in theory, but too slow in practice"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DQAOlERnYiiw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d6b808e8-a303-4e88-84dc-05b5933de546"
      },
      "source": [
        "column  = 'quantity'\n",
        "\n",
        "# Fit without column\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "pipeline.fit(X_train.drop(columns=column), y_train)\n",
        "score_without = pipeline.score(X_val.drop(columns=column), y_val)\n",
        "print(f'Validation Accuracy without {column}: {score_without}')\n",
        "\n",
        "# Fit with column\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "pipeline.fit(X_train, y_train)\n",
        "score_with = pipeline.score(X_val, y_val)\n",
        "print(f'Validation Accuracy with {column}: {score_with}')\n",
        "\n",
        "# Compare the error with & without column\n",
        "print(f'Drop-Column Importance for {column}: {score_with - score_without}')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy without quantity: 0.7771043771043771\n",
            "Validation Accuracy with quantity: 0.8135521885521886\n",
            "Drop-Column Importance for quantity: 0.03644781144781151\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6Vu39wGkYiix"
      },
      "source": [
        "## 3. Permutation Importance\n",
        "\n",
        "Permutation Importance is a good compromise between Feature Importance based on impurity reduction (which is the fastest) and Drop Column Importance (which is the \"best.\")\n",
        "\n",
        "[The ELI5 library documentation explains,](https://eli5.readthedocs.io/en/latest/blackbox/permutation_importance.html)\n",
        "\n",
        "> Importance can be measured by looking at how much the score (accuracy, F1, R^2, etc. - any score we’re interested in) decreases when a feature is not available.\n",
        ">\n",
        "> To do that one can remove feature from the dataset, re-train the estimator and check the score. But it requires re-training an estimator for each feature, which can be computationally intensive. ...\n",
        ">\n",
        ">To avoid re-training the estimator we can remove a feature only from the test part of the dataset, and compute score without using this feature. It doesn’t work as-is, because estimators expect feature to be present. So instead of removing a feature we can replace it with random noise - feature column is still there, but it no longer contains useful information. This method works if noise is drawn from the same distribution as original feature values (as otherwise estimator may fail). The simplest way to get such noise is to shuffle values for a feature, i.e. use other examples’ feature values - this is how permutation importance is computed.\n",
        ">\n",
        ">The method is most suitable for computing feature importances when a number of columns (features) is not huge; it can be resource-intensive otherwise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GYCiEx7zYiiy"
      },
      "source": [
        "### Do-It-Yourself way, for intuition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TksOf_n2Yiiy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "a4169e4e-e0ee-431d-f113-9a8b42c4fef1"
      },
      "source": [
        "#Before : Order\n",
        "feature = 'quantity'\n",
        "X_val[feature].head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3290     insufficient\n",
              "47666    insufficient\n",
              "2538           enough\n",
              "53117          enough\n",
              "51817          enough\n",
              "Name: quantity, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCSzdt3PFcp8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "4b28cba3-cdad-4aa7-ee71-dc6fccbd5ce6"
      },
      "source": [
        "#Before: Distribution\n",
        "X_val[feature].value_counts()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "enough          6619\n",
              "insufficient    2976\n",
              "dry             1325\n",
              "seasonal         806\n",
              "unknown          154\n",
              "Name: quantity, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bO0k0o5FlBb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PERMUTE!\n",
        "X_val_permuted = X_val.copy()\n",
        "X_val_permuted[feature] = np.random.permutation(X_val[feature])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1p06G2VfGlZB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "12593f0a-ccbe-456e-8df8-dddf1a02bcec"
      },
      "source": [
        "# AFTER: Sequence has changed!\n",
        "X_val_permuted[feature].head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3290       enough\n",
              "47666      enough\n",
              "2538          dry\n",
              "53117      enough\n",
              "51817    seasonal\n",
              "Name: quantity, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsnjsx1uF6Jf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "5376139a-b42e-4784-8ebe-5612decc7755"
      },
      "source": [
        "# AFTER: Distribution hasn't changed!\n",
        "X_val_permuted[feature].value_counts()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "enough          6619\n",
              "insufficient    2976\n",
              "dry             1325\n",
              "seasonal         806\n",
              "unknown          154\n",
              "Name: quantity, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOf53fgCGANM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "29a0fced-ab4a-4605-81dd-e0c71456a8c0"
      },
      "source": [
        "#Get the permutaion importance \n",
        "#Notice that we don't need to refit the pipeline here \n",
        "score_permuted = pipeline.score(X_val_permuted, y_val)\n",
        "\n",
        "print(f'Validation Accuracy with {feature}: {score_with}')\n",
        "print(f'Validation Accuracy with {feature} permuted: {score_permuted}')\n",
        "print(f'Permutation Importance: {score_with - score_permuted}')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy with quantity: 0.8135521885521886\n",
            "Validation Accuracy with quantity permuted: 0.7070707070707071\n",
            "Permutation Importance: 0.10648148148148151\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3O4r9bD1G63_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "8c2fd67e-537a-4d86-d8dc-3eda2e99f485"
      },
      "source": [
        "# Rerun the permutation importance process, but for a different feature\n",
        "feature = 'wpt_name'\n",
        "X_val_permuted = X_val.copy()\n",
        "X_val_permuted[feature] = np.random.permutation(X_val[feature])\n",
        "score_permuted = pipeline.score(X_val_permuted, y_val)\n",
        "\n",
        "print(f'Validation Accuracy with {feature}: {score_with}')\n",
        "print(f'Validation Accuracy with {feature} permuted: {score_permuted}')\n",
        "print(f'Permutation Importance: {score_with - score_permuted}')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy with wpt_name: 0.8135521885521886\n",
            "Validation Accuracy with wpt_name permuted: 0.8121212121212121\n",
            "Permutation Importance: 0.0014309764309764494\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0LYk19SNYii7"
      },
      "source": [
        "### With eli5 library\n",
        "\n",
        "For more documentation on using this library, see:\n",
        "- [eli5.sklearn.PermutationImportance](https://eli5.readthedocs.io/en/latest/autodocs/sklearn.html#eli5.sklearn.permutation_importance.PermutationImportance)\n",
        "- [eli5.show_weights](https://eli5.readthedocs.io/en/latest/autodocs/eli5.html#eli5.show_weights)\n",
        "- [scikit-learn user guide, `scoring` parameter](https://scikit-learn.org/stable/modules/model_evaluation.html#the-scoring-parameter-defining-model-evaluation-rules)\n",
        "\n",
        "eli5 doesn't work with pipelines."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpSemTkFFP8i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "7fcc012e-394c-40c0-93a0-13cbe62a9f0c"
      },
      "source": [
        "transformers = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median')\n",
        ")\n",
        "\n",
        "X_train_transformed = transformers.fit_transform(X_train)\n",
        "X_val_transformed = transformers.transform(X_val)\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "model.fit(X_train_transformed, y_train)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=-1, oob_score=False, random_state=42, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qNnovdmIVti",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "outputId": "ce5068d3-b8e3-4932-e114-6e774f52a3c1"
      },
      "source": [
        "import eli5\n",
        "from eli5.sklearn import PermutationImportance\n",
        "\n",
        "permuter = PermutationImportance(\n",
        "    model,\n",
        "    scoring='accuracy', \n",
        "    n_iter=2, \n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "permuter.fit(X_val_transformed, y_val)\n",
        "feature_names = X_val.columns.tolist()\n",
        "\n",
        "eli5.show_weights(\n",
        "    permuter, \n",
        "    top=None, # show permutation importances for all features\n",
        "    feature_names=feature_names\n",
        ")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
              "    <thead>\n",
              "    <tr style=\"border: none;\">\n",
              "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
              "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "    </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.1005\n",
              "                \n",
              "                    &plusmn; 0.0003\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                quantity\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 95.88%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0105\n",
              "                \n",
              "                    &plusmn; 0.0005\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                amount_tsh\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 95.92%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0104\n",
              "                \n",
              "                    &plusmn; 0.0012\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                waterpoint_type\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 96.02%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0100\n",
              "                \n",
              "                    &plusmn; 0.0005\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                extraction_type_class\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 96.15%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0096\n",
              "                \n",
              "                    &plusmn; 0.0013\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                longitude\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 96.74%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0075\n",
              "                \n",
              "                    &plusmn; 0.0019\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                latitude\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 96.89%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0070\n",
              "                \n",
              "                    &plusmn; 0.0011\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                waterpoint_type_group\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 97.09%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0064\n",
              "                \n",
              "                    &plusmn; 0.0003\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                population\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.08%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0035\n",
              "                \n",
              "                    &plusmn; 0.0034\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                construction_year\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.28%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0030\n",
              "                \n",
              "                    &plusmn; 0.0035\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                years\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.33%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0029\n",
              "                \n",
              "                    &plusmn; 0.0006\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                public_meeting\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.36%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0028\n",
              "                \n",
              "                    &plusmn; 0.0011\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                subvillage\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.36%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0028\n",
              "                \n",
              "                    &plusmn; 0.0013\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                payment\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.57%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0023\n",
              "                \n",
              "                    &plusmn; 0.0018\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                day_recorded\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.80%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0018\n",
              "                \n",
              "                    &plusmn; 0.0004\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                gps_height\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.88%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0016\n",
              "                \n",
              "                    &plusmn; 0.0008\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                source\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.94%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0015\n",
              "                \n",
              "                    &plusmn; 0.0008\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                district_code\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0014\n",
              "                \n",
              "                    &plusmn; 0.0008\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                extraction_type_group\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.18%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0011\n",
              "                \n",
              "                    &plusmn; 0.0016\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                region\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.25%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0009\n",
              "                \n",
              "                    &plusmn; 0.0010\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                longitude_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.27%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0009\n",
              "                \n",
              "                    &plusmn; 0.0006\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                extraction_type\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.32%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0008\n",
              "                \n",
              "                    &plusmn; 0.0006\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                ward\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.35%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0008\n",
              "                \n",
              "                    &plusmn; 0.0010\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                year_recorded\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.35%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0008\n",
              "                \n",
              "                    &plusmn; 0.0007\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                wpt_name\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.37%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0007\n",
              "                \n",
              "                    &plusmn; 0.0011\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                water_quality\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.40%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0007\n",
              "                \n",
              "                    &plusmn; 0.0005\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                years_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.40%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0007\n",
              "                \n",
              "                    &plusmn; 0.0005\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                permit\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.42%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0006\n",
              "                \n",
              "                    &plusmn; 0.0004\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                funder\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.45%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0006\n",
              "                \n",
              "                    &plusmn; 0.0010\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                source_class\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.48%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0005\n",
              "                \n",
              "                    &plusmn; 0.0009\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                lga\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.48%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0005\n",
              "                \n",
              "                    &plusmn; 0.0014\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                region_code\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.51%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0005\n",
              "                \n",
              "                    &plusmn; 0.0024\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                management\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.54%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0005\n",
              "                \n",
              "                    &plusmn; 0.0021\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                month_recorded\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.57%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0004\n",
              "                \n",
              "                    &plusmn; 0.0007\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                construction_year_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.63%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0003\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                num_private\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.70%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0003\n",
              "                \n",
              "                    &plusmn; 0.0003\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                population_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.81%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0001\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                latitude_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.91%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0000\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                source_type\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.77%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0002\n",
              "                \n",
              "                    &plusmn; 0.0003\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                scheme_name\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.77%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0002\n",
              "                \n",
              "                    &plusmn; 0.0013\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                scheme_management\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.77%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0002\n",
              "                \n",
              "                    &plusmn; 0.0003\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                management_group\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.77%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0002\n",
              "                \n",
              "                    &plusmn; 0.0007\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                gps_height_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.32%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0008\n",
              "                \n",
              "                    &plusmn; 0.0013\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                installer\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.27%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0009\n",
              "                \n",
              "                    &plusmn; 0.0011\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                quality_group\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 98.78%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0019\n",
              "                \n",
              "                    &plusmn; 0.0008\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                basin\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "    \n",
              "    </tbody>\n",
              "</table>\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q07yW9k-Yii8"
      },
      "source": [
        "### We can use importances for feature selection\n",
        "\n",
        "For example, we can remove features with zero importance. The model trains faster and the score does not decrease."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tZrPFyEMYii9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9163cf24-1734-4aed-b788-2604bdc02bbd"
      },
      "source": [
        "print('Shape before removing features:', X_train.shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape before removing features: (47520, 45)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKzSxiDVPTZ4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "156d11bf-d310-4089-9c01-d230eafad36d"
      },
      "source": [
        "minimum_importance = 0\n",
        "mask = permuter.feature_importances_ > minimum_importance\n",
        "features = X_train.columns[mask]\n",
        "X_train = X_train[features]\n",
        "\n",
        "print('Shape after removing features:', X_train.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape after removing features: (47520, 37)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsnJRKjfWYph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_val = X_val[features]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhRwoe4iPY2E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4e9466a6-e8e3-47d1-81c8-e6b0a9cb51f6"
      },
      "source": [
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "\n",
        "# Fit on train, score on val\n",
        "pipeline.fit(X_train, y_train)\n",
        "print('Validation Accuracy', pipeline.score(X_val, y_val))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.8138047138047138\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fl67bCR7WY6j",
        "colab_type": "text"
      },
      "source": [
        "## Use xgboost for gradient boosting\n",
        "\n",
        "#### [XGBoost Python API Reference: Scikit-Learn API](https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miW903OyPmGT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "5c5f4221-b80f-4f51-a742-807f9f752e76"
      },
      "source": [
        "# from s\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    XGBClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "\n",
        "pipeline.fit(X_train, y_train)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('ordinalencoder',\n",
              "                 OrdinalEncoder(cols=['funder', 'wpt_name', 'subvillage',\n",
              "                                      'region', 'lga', 'ward', 'public_meeting',\n",
              "                                      'permit', 'extraction_type',\n",
              "                                      'extraction_type_group',\n",
              "                                      'extraction_type_class', 'management',\n",
              "                                      'payment', 'water_quality', 'quantity',\n",
              "                                      'source', 'source_class',\n",
              "                                      'waterpoint_type',\n",
              "                                      'waterpoint_type_group'],\n",
              "                                drop_invariant=Fals...\n",
              "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
              "                               colsample_bylevel=1, colsample_bynode=1,\n",
              "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
              "                               max_delta_step=0, max_depth=3,\n",
              "                               min_child_weight=1, missing=None,\n",
              "                               n_estimators=100, n_jobs=-1, nthread=None,\n",
              "                               objective='multi:softprob', random_state=42,\n",
              "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
              "                               seed=None, silent=None, subsample=1,\n",
              "                               verbosity=1))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIBZ6rh1QbGU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d36cab03-5cc1-46ff-e187-9c717e7809d1"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "y_pred = pipeline.predict(X_val)\n",
        "print('Validation Accuracy', accuracy_score(y_val, y_pred))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.7454545454545455\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ubb7Ot6OZcK1",
        "colab_type": "text"
      },
      "source": [
        "### Understand the difference between boosting & bagging\n",
        "\n",
        "Boosting (used by Gradient Boosting) is different than Bagging (used by Random Forests). \n",
        "\n",
        "[_An Introduction to Statistical Learning_](http://www-bcf.usc.edu/~gareth/ISL/ISLR%20Seventh%20Printing.pdf) Chapter 8.2.3, Boosting:\n",
        "\n",
        ">Recall that bagging involves creating multiple copies of the original training data set using the bootstrap, fitting a separate decision tree to each copy, and then combining all of the trees in order to create a single predictive model.\n",
        ">\n",
        ">**Boosting works in a similar way, except that the trees are grown _sequentially_: each tree is grown using information from previously grown trees.**\n",
        ">\n",
        ">Unlike fitting a single large decision tree to the data, which amounts to _fitting the data hard_ and potentially overfitting, the boosting approach instead _learns slowly._ Given the current model, we fit a decision tree to the residuals from the model.\n",
        ">\n",
        ">We then add this new decision tree into the fitted function in order to update the residuals. Each of these trees can be rather small, with just a few terminal nodes. **By fitting small trees to the residuals, we slowly improve fˆ in areas where it does not perform well.**\n",
        ">\n",
        ">Note that in boosting, unlike in bagging, the construction of each tree depends strongly on the trees that have already been grown."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCjVSlD_XJr2",
        "colab_type": "text"
      },
      "source": [
        "#### [Avoid Overfitting By Early Stopping With XGBoost In Python](https://machinelearningmastery.com/avoid-overfitting-by-early-stopping-with-xgboost-in-python/)\n",
        "\n",
        "Why is early stopping better than a For loop, or GridSearchCV, to optimize `n_estimators`?\n",
        "\n",
        "With early stopping, if `n_iterations` is our number of iterations, then we fit `n_iterations` decision trees.\n",
        "\n",
        "With a for loop, or GridSearchCV, we'd fit `sum(range(1,n_rounds+1))` trees.\n",
        "\n",
        "But it doesn't work well with pipelines. You may need to re-run multiple times with different values of other parameters such as `max_depth` and `learning_rate`.\n",
        "\n",
        "#### XGBoost parameters\n",
        "- [Notes on parameter tuning](https://xgboost.readthedocs.io/en/latest/tutorials/param_tuning.html)\n",
        "- [Parameters documentation](https://xgboost.readthedocs.io/en/latest/parameter.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNX3IKftXBFS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "85b43b93-fae1-49a7-809f-1e3b9b68b892"
      },
      "source": [
        "encoder = ce.OrdinalEncoder()\n",
        "X_train_encoded = encoder.fit_transform(X_train)\n",
        "X_val_encoded = encoder.transform(X_val)\n",
        "\n",
        "X_train.shape, X_val.shape, X_train_encoded.shape, X_val_encoded.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((47520, 37), (11880, 37), (47520, 37), (11880, 37))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JU_asWSvTNtx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b92368f3-75f6-408a-8dc6-ef72f6c0bab0"
      },
      "source": [
        "eval_set = [(X_train_encoded, y_train), \n",
        "            (X_val_encoded, y_val)]\n",
        "\n",
        "model = XGBClassifier(\n",
        "    n_estimators=1000, # <= 1000 trees, depends on early stopping\n",
        "    max_depth=7,       # try deeper trees because of high cardinality categoricals\n",
        "    learning_rate=0.1, # try higher learning rate\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "model.fit(X_train_encoded, y_train, eval_set=eval_set, \n",
        "          eval_metric='merror', early_stopping_rounds=50)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-merror:0.250821\tvalidation_1-merror:0.261027\n",
            "Multiple eval metrics have been passed: 'validation_1-merror' will be used for early stopping.\n",
            "\n",
            "Will train until validation_1-merror hasn't improved in 50 rounds.\n",
            "[1]\tvalidation_0-merror:0.251284\tvalidation_1-merror:0.262795\n",
            "[2]\tvalidation_0-merror:0.252315\tvalidation_1-merror:0.264562\n",
            "[3]\tvalidation_0-merror:0.2504\tvalidation_1-merror:0.26229\n",
            "[4]\tvalidation_0-merror:0.249916\tvalidation_1-merror:0.261448\n",
            "[5]\tvalidation_0-merror:0.246191\tvalidation_1-merror:0.257239\n",
            "[6]\tvalidation_0-merror:0.244171\tvalidation_1-merror:0.253704\n",
            "[7]\tvalidation_0-merror:0.241246\tvalidation_1-merror:0.251515\n",
            "[8]\tvalidation_0-merror:0.237879\tvalidation_1-merror:0.248401\n",
            "[9]\tvalidation_0-merror:0.237037\tvalidation_1-merror:0.247811\n",
            "[10]\tvalidation_0-merror:0.23609\tvalidation_1-merror:0.24697\n",
            "[11]\tvalidation_0-merror:0.234912\tvalidation_1-merror:0.246549\n",
            "[12]\tvalidation_0-merror:0.234154\tvalidation_1-merror:0.246128\n",
            "[13]\tvalidation_0-merror:0.233544\tvalidation_1-merror:0.245455\n",
            "[14]\tvalidation_0-merror:0.232176\tvalidation_1-merror:0.243687\n",
            "[15]\tvalidation_0-merror:0.231187\tvalidation_1-merror:0.243098\n",
            "[16]\tvalidation_0-merror:0.230324\tvalidation_1-merror:0.241751\n",
            "[17]\tvalidation_0-merror:0.228872\tvalidation_1-merror:0.240657\n",
            "[18]\tvalidation_0-merror:0.228199\tvalidation_1-merror:0.24133\n",
            "[19]\tvalidation_0-merror:0.227399\tvalidation_1-merror:0.239394\n",
            "[20]\tvalidation_0-merror:0.226094\tvalidation_1-merror:0.239815\n",
            "[21]\tvalidation_0-merror:0.224811\tvalidation_1-merror:0.238047\n",
            "[22]\tvalidation_0-merror:0.224011\tvalidation_1-merror:0.236448\n",
            "[23]\tvalidation_0-merror:0.222875\tvalidation_1-merror:0.236195\n",
            "[24]\tvalidation_0-merror:0.22218\tvalidation_1-merror:0.235859\n",
            "[25]\tvalidation_0-merror:0.221233\tvalidation_1-merror:0.235017\n",
            "[26]\tvalidation_0-merror:0.219907\tvalidation_1-merror:0.233838\n",
            "[27]\tvalidation_0-merror:0.218056\tvalidation_1-merror:0.232576\n",
            "[28]\tvalidation_0-merror:0.217003\tvalidation_1-merror:0.231397\n",
            "[29]\tvalidation_0-merror:0.215278\tvalidation_1-merror:0.230051\n",
            "[30]\tvalidation_0-merror:0.212689\tvalidation_1-merror:0.229209\n",
            "[31]\tvalidation_0-merror:0.211806\tvalidation_1-merror:0.227694\n",
            "[32]\tvalidation_0-merror:0.210417\tvalidation_1-merror:0.227694\n",
            "[33]\tvalidation_0-merror:0.208628\tvalidation_1-merror:0.226768\n",
            "[34]\tvalidation_0-merror:0.207513\tvalidation_1-merror:0.225842\n",
            "[35]\tvalidation_0-merror:0.206608\tvalidation_1-merror:0.225505\n",
            "[36]\tvalidation_0-merror:0.205114\tvalidation_1-merror:0.224916\n",
            "[37]\tvalidation_0-merror:0.203872\tvalidation_1-merror:0.224579\n",
            "[38]\tvalidation_0-merror:0.203409\tvalidation_1-merror:0.224411\n",
            "[39]\tvalidation_0-merror:0.202778\tvalidation_1-merror:0.223485\n",
            "[40]\tvalidation_0-merror:0.201684\tvalidation_1-merror:0.222138\n",
            "[41]\tvalidation_0-merror:0.200821\tvalidation_1-merror:0.222306\n",
            "[42]\tvalidation_0-merror:0.199579\tvalidation_1-merror:0.22037\n",
            "[43]\tvalidation_0-merror:0.198316\tvalidation_1-merror:0.220707\n",
            "[44]\tvalidation_0-merror:0.19718\tvalidation_1-merror:0.219865\n",
            "[45]\tvalidation_0-merror:0.196317\tvalidation_1-merror:0.219529\n",
            "[46]\tvalidation_0-merror:0.196233\tvalidation_1-merror:0.218771\n",
            "[47]\tvalidation_0-merror:0.194971\tvalidation_1-merror:0.218603\n",
            "[48]\tvalidation_0-merror:0.193308\tvalidation_1-merror:0.217508\n",
            "[49]\tvalidation_0-merror:0.192593\tvalidation_1-merror:0.217508\n",
            "[50]\tvalidation_0-merror:0.191856\tvalidation_1-merror:0.21633\n",
            "[51]\tvalidation_0-merror:0.191372\tvalidation_1-merror:0.216667\n",
            "[52]\tvalidation_0-merror:0.190467\tvalidation_1-merror:0.216582\n",
            "[53]\tvalidation_0-merror:0.189941\tvalidation_1-merror:0.216246\n",
            "[54]\tvalidation_0-merror:0.189415\tvalidation_1-merror:0.21633\n",
            "[55]\tvalidation_0-merror:0.18891\tvalidation_1-merror:0.216077\n",
            "[56]\tvalidation_0-merror:0.188447\tvalidation_1-merror:0.215488\n",
            "[57]\tvalidation_0-merror:0.187689\tvalidation_1-merror:0.214899\n",
            "[58]\tvalidation_0-merror:0.18729\tvalidation_1-merror:0.215152\n",
            "[59]\tvalidation_0-merror:0.186848\tvalidation_1-merror:0.214899\n",
            "[60]\tvalidation_0-merror:0.186742\tvalidation_1-merror:0.214983\n",
            "[61]\tvalidation_0-merror:0.18588\tvalidation_1-merror:0.214057\n",
            "[62]\tvalidation_0-merror:0.185227\tvalidation_1-merror:0.2133\n",
            "[63]\tvalidation_0-merror:0.184322\tvalidation_1-merror:0.212121\n",
            "[64]\tvalidation_0-merror:0.18407\tvalidation_1-merror:0.212205\n",
            "[65]\tvalidation_0-merror:0.183733\tvalidation_1-merror:0.212205\n",
            "[66]\tvalidation_0-merror:0.183333\tvalidation_1-merror:0.21271\n",
            "[67]\tvalidation_0-merror:0.182765\tvalidation_1-merror:0.212542\n",
            "[68]\tvalidation_0-merror:0.182323\tvalidation_1-merror:0.21229\n",
            "[69]\tvalidation_0-merror:0.181524\tvalidation_1-merror:0.211448\n",
            "[70]\tvalidation_0-merror:0.180997\tvalidation_1-merror:0.211111\n",
            "[71]\tvalidation_0-merror:0.180492\tvalidation_1-merror:0.211195\n",
            "[72]\tvalidation_0-merror:0.180156\tvalidation_1-merror:0.210774\n",
            "[73]\tvalidation_0-merror:0.179861\tvalidation_1-merror:0.210438\n",
            "[74]\tvalidation_0-merror:0.179125\tvalidation_1-merror:0.210269\n",
            "[75]\tvalidation_0-merror:0.178683\tvalidation_1-merror:0.210354\n",
            "[76]\tvalidation_0-merror:0.178241\tvalidation_1-merror:0.209764\n",
            "[77]\tvalidation_0-merror:0.177694\tvalidation_1-merror:0.209259\n",
            "[78]\tvalidation_0-merror:0.177189\tvalidation_1-merror:0.209175\n",
            "[79]\tvalidation_0-merror:0.176768\tvalidation_1-merror:0.209091\n",
            "[80]\tvalidation_0-merror:0.176473\tvalidation_1-merror:0.209091\n",
            "[81]\tvalidation_0-merror:0.175779\tvalidation_1-merror:0.20867\n",
            "[82]\tvalidation_0-merror:0.175274\tvalidation_1-merror:0.208249\n",
            "[83]\tvalidation_0-merror:0.175295\tvalidation_1-merror:0.208502\n",
            "[84]\tvalidation_0-merror:0.174453\tvalidation_1-merror:0.207828\n",
            "[85]\tvalidation_0-merror:0.174011\tvalidation_1-merror:0.207576\n",
            "[86]\tvalidation_0-merror:0.173674\tvalidation_1-merror:0.207492\n",
            "[87]\tvalidation_0-merror:0.173359\tvalidation_1-merror:0.207744\n",
            "[88]\tvalidation_0-merror:0.172917\tvalidation_1-merror:0.207912\n",
            "[89]\tvalidation_0-merror:0.173064\tvalidation_1-merror:0.207744\n",
            "[90]\tvalidation_0-merror:0.172517\tvalidation_1-merror:0.207828\n",
            "[91]\tvalidation_0-merror:0.171738\tvalidation_1-merror:0.207323\n",
            "[92]\tvalidation_0-merror:0.171633\tvalidation_1-merror:0.207155\n",
            "[93]\tvalidation_0-merror:0.171402\tvalidation_1-merror:0.207323\n",
            "[94]\tvalidation_0-merror:0.171044\tvalidation_1-merror:0.207828\n",
            "[95]\tvalidation_0-merror:0.170749\tvalidation_1-merror:0.207828\n",
            "[96]\tvalidation_0-merror:0.170476\tvalidation_1-merror:0.208081\n",
            "[97]\tvalidation_0-merror:0.170412\tvalidation_1-merror:0.207576\n",
            "[98]\tvalidation_0-merror:0.169823\tvalidation_1-merror:0.207323\n",
            "[99]\tvalidation_0-merror:0.169613\tvalidation_1-merror:0.207239\n",
            "[100]\tvalidation_0-merror:0.169129\tvalidation_1-merror:0.206734\n",
            "[101]\tvalidation_0-merror:0.169003\tvalidation_1-merror:0.206902\n",
            "[102]\tvalidation_0-merror:0.168729\tvalidation_1-merror:0.206566\n",
            "[103]\tvalidation_0-merror:0.167908\tvalidation_1-merror:0.206061\n",
            "[104]\tvalidation_0-merror:0.167551\tvalidation_1-merror:0.205808\n",
            "[105]\tvalidation_0-merror:0.167319\tvalidation_1-merror:0.205724\n",
            "[106]\tvalidation_0-merror:0.166961\tvalidation_1-merror:0.206229\n",
            "[107]\tvalidation_0-merror:0.166288\tvalidation_1-merror:0.20564\n",
            "[108]\tvalidation_0-merror:0.165614\tvalidation_1-merror:0.205724\n",
            "[109]\tvalidation_0-merror:0.165236\tvalidation_1-merror:0.205808\n",
            "[110]\tvalidation_0-merror:0.164878\tvalidation_1-merror:0.205808\n",
            "[111]\tvalidation_0-merror:0.164394\tvalidation_1-merror:0.20564\n",
            "[112]\tvalidation_0-merror:0.164183\tvalidation_1-merror:0.205892\n",
            "[113]\tvalidation_0-merror:0.163594\tvalidation_1-merror:0.205976\n",
            "[114]\tvalidation_0-merror:0.163615\tvalidation_1-merror:0.205892\n",
            "[115]\tvalidation_0-merror:0.163321\tvalidation_1-merror:0.20564\n",
            "[116]\tvalidation_0-merror:0.162837\tvalidation_1-merror:0.205556\n",
            "[117]\tvalidation_0-merror:0.162984\tvalidation_1-merror:0.205724\n",
            "[118]\tvalidation_0-merror:0.162668\tvalidation_1-merror:0.205556\n",
            "[119]\tvalidation_0-merror:0.162226\tvalidation_1-merror:0.205387\n",
            "[120]\tvalidation_0-merror:0.161574\tvalidation_1-merror:0.205724\n",
            "[121]\tvalidation_0-merror:0.161048\tvalidation_1-merror:0.205724\n",
            "[122]\tvalidation_0-merror:0.161027\tvalidation_1-merror:0.205724\n",
            "[123]\tvalidation_0-merror:0.160838\tvalidation_1-merror:0.205724\n",
            "[124]\tvalidation_0-merror:0.160122\tvalidation_1-merror:0.205219\n",
            "[125]\tvalidation_0-merror:0.15968\tvalidation_1-merror:0.204966\n",
            "[126]\tvalidation_0-merror:0.159596\tvalidation_1-merror:0.20505\n",
            "[127]\tvalidation_0-merror:0.159007\tvalidation_1-merror:0.205303\n",
            "[128]\tvalidation_0-merror:0.158754\tvalidation_1-merror:0.205387\n",
            "[129]\tvalidation_0-merror:0.15846\tvalidation_1-merror:0.20505\n",
            "[130]\tvalidation_0-merror:0.158039\tvalidation_1-merror:0.204882\n",
            "[131]\tvalidation_0-merror:0.157702\tvalidation_1-merror:0.20505\n",
            "[132]\tvalidation_0-merror:0.157449\tvalidation_1-merror:0.204966\n",
            "[133]\tvalidation_0-merror:0.157281\tvalidation_1-merror:0.205471\n",
            "[134]\tvalidation_0-merror:0.156881\tvalidation_1-merror:0.205471\n",
            "[135]\tvalidation_0-merror:0.156734\tvalidation_1-merror:0.205387\n",
            "[136]\tvalidation_0-merror:0.15646\tvalidation_1-merror:0.205135\n",
            "[137]\tvalidation_0-merror:0.156376\tvalidation_1-merror:0.205219\n",
            "[138]\tvalidation_0-merror:0.155787\tvalidation_1-merror:0.204798\n",
            "[139]\tvalidation_0-merror:0.155619\tvalidation_1-merror:0.205556\n",
            "[140]\tvalidation_0-merror:0.15484\tvalidation_1-merror:0.205724\n",
            "[141]\tvalidation_0-merror:0.154672\tvalidation_1-merror:0.205724\n",
            "[142]\tvalidation_0-merror:0.154609\tvalidation_1-merror:0.20564\n",
            "[143]\tvalidation_0-merror:0.154356\tvalidation_1-merror:0.205471\n",
            "[144]\tvalidation_0-merror:0.154019\tvalidation_1-merror:0.20564\n",
            "[145]\tvalidation_0-merror:0.153367\tvalidation_1-merror:0.205471\n",
            "[146]\tvalidation_0-merror:0.152925\tvalidation_1-merror:0.205471\n",
            "[147]\tvalidation_0-merror:0.152757\tvalidation_1-merror:0.205387\n",
            "[148]\tvalidation_0-merror:0.152525\tvalidation_1-merror:0.205135\n",
            "[149]\tvalidation_0-merror:0.152378\tvalidation_1-merror:0.205387\n",
            "[150]\tvalidation_0-merror:0.152231\tvalidation_1-merror:0.205471\n",
            "[151]\tvalidation_0-merror:0.151915\tvalidation_1-merror:0.205556\n",
            "[152]\tvalidation_0-merror:0.151452\tvalidation_1-merror:0.205303\n",
            "[153]\tvalidation_0-merror:0.151094\tvalidation_1-merror:0.204714\n",
            "[154]\tvalidation_0-merror:0.150842\tvalidation_1-merror:0.204377\n",
            "[155]\tvalidation_0-merror:0.150358\tvalidation_1-merror:0.204209\n",
            "[156]\tvalidation_0-merror:0.150231\tvalidation_1-merror:0.203956\n",
            "[157]\tvalidation_0-merror:0.149705\tvalidation_1-merror:0.203535\n",
            "[158]\tvalidation_0-merror:0.149411\tvalidation_1-merror:0.203367\n",
            "[159]\tvalidation_0-merror:0.149369\tvalidation_1-merror:0.203367\n",
            "[160]\tvalidation_0-merror:0.149032\tvalidation_1-merror:0.203199\n",
            "[161]\tvalidation_0-merror:0.148758\tvalidation_1-merror:0.203283\n",
            "[162]\tvalidation_0-merror:0.148464\tvalidation_1-merror:0.203451\n",
            "[163]\tvalidation_0-merror:0.147917\tvalidation_1-merror:0.203199\n",
            "[164]\tvalidation_0-merror:0.147496\tvalidation_1-merror:0.20362\n",
            "[165]\tvalidation_0-merror:0.147096\tvalidation_1-merror:0.20362\n",
            "[166]\tvalidation_0-merror:0.147117\tvalidation_1-merror:0.203872\n",
            "[167]\tvalidation_0-merror:0.146338\tvalidation_1-merror:0.203199\n",
            "[168]\tvalidation_0-merror:0.146044\tvalidation_1-merror:0.203283\n",
            "[169]\tvalidation_0-merror:0.145749\tvalidation_1-merror:0.203367\n",
            "[170]\tvalidation_0-merror:0.145581\tvalidation_1-merror:0.203367\n",
            "[171]\tvalidation_0-merror:0.14516\tvalidation_1-merror:0.202441\n",
            "[172]\tvalidation_0-merror:0.145244\tvalidation_1-merror:0.202189\n",
            "[173]\tvalidation_0-merror:0.144992\tvalidation_1-merror:0.202778\n",
            "[174]\tvalidation_0-merror:0.144634\tvalidation_1-merror:0.202441\n",
            "[175]\tvalidation_0-merror:0.144318\tvalidation_1-merror:0.202525\n",
            "[176]\tvalidation_0-merror:0.144024\tvalidation_1-merror:0.202609\n",
            "[177]\tvalidation_0-merror:0.143476\tvalidation_1-merror:0.202862\n",
            "[178]\tvalidation_0-merror:0.14314\tvalidation_1-merror:0.20303\n",
            "[179]\tvalidation_0-merror:0.142698\tvalidation_1-merror:0.203199\n",
            "[180]\tvalidation_0-merror:0.142529\tvalidation_1-merror:0.202862\n",
            "[181]\tvalidation_0-merror:0.142045\tvalidation_1-merror:0.202525\n",
            "[182]\tvalidation_0-merror:0.141793\tvalidation_1-merror:0.201515\n",
            "[183]\tvalidation_0-merror:0.141519\tvalidation_1-merror:0.201684\n",
            "[184]\tvalidation_0-merror:0.141519\tvalidation_1-merror:0.201768\n",
            "[185]\tvalidation_0-merror:0.141309\tvalidation_1-merror:0.201852\n",
            "[186]\tvalidation_0-merror:0.140909\tvalidation_1-merror:0.201852\n",
            "[187]\tvalidation_0-merror:0.140614\tvalidation_1-merror:0.201515\n",
            "[188]\tvalidation_0-merror:0.140488\tvalidation_1-merror:0.201599\n",
            "[189]\tvalidation_0-merror:0.140278\tvalidation_1-merror:0.202273\n",
            "[190]\tvalidation_0-merror:0.13992\tvalidation_1-merror:0.202357\n",
            "[191]\tvalidation_0-merror:0.139646\tvalidation_1-merror:0.202441\n",
            "[192]\tvalidation_0-merror:0.139478\tvalidation_1-merror:0.202189\n",
            "[193]\tvalidation_0-merror:0.139373\tvalidation_1-merror:0.202441\n",
            "[194]\tvalidation_0-merror:0.139099\tvalidation_1-merror:0.20202\n",
            "[195]\tvalidation_0-merror:0.13912\tvalidation_1-merror:0.202104\n",
            "[196]\tvalidation_0-merror:0.1387\tvalidation_1-merror:0.201936\n",
            "[197]\tvalidation_0-merror:0.138594\tvalidation_1-merror:0.202104\n",
            "[198]\tvalidation_0-merror:0.137984\tvalidation_1-merror:0.201684\n",
            "[199]\tvalidation_0-merror:0.137921\tvalidation_1-merror:0.201852\n",
            "[200]\tvalidation_0-merror:0.137668\tvalidation_1-merror:0.202273\n",
            "[201]\tvalidation_0-merror:0.137563\tvalidation_1-merror:0.202189\n",
            "[202]\tvalidation_0-merror:0.137205\tvalidation_1-merror:0.202104\n",
            "[203]\tvalidation_0-merror:0.136932\tvalidation_1-merror:0.202694\n",
            "[204]\tvalidation_0-merror:0.136721\tvalidation_1-merror:0.202609\n",
            "[205]\tvalidation_0-merror:0.136406\tvalidation_1-merror:0.202525\n",
            "[206]\tvalidation_0-merror:0.136069\tvalidation_1-merror:0.202189\n",
            "[207]\tvalidation_0-merror:0.13548\tvalidation_1-merror:0.202273\n",
            "[208]\tvalidation_0-merror:0.135227\tvalidation_1-merror:0.202946\n",
            "[209]\tvalidation_0-merror:0.13508\tvalidation_1-merror:0.203283\n",
            "[210]\tvalidation_0-merror:0.134407\tvalidation_1-merror:0.203199\n",
            "[211]\tvalidation_0-merror:0.134091\tvalidation_1-merror:0.203283\n",
            "[212]\tvalidation_0-merror:0.133965\tvalidation_1-merror:0.203199\n",
            "[213]\tvalidation_0-merror:0.133607\tvalidation_1-merror:0.202862\n",
            "[214]\tvalidation_0-merror:0.133375\tvalidation_1-merror:0.202778\n",
            "[215]\tvalidation_0-merror:0.133207\tvalidation_1-merror:0.202778\n",
            "[216]\tvalidation_0-merror:0.132933\tvalidation_1-merror:0.202189\n",
            "[217]\tvalidation_0-merror:0.132807\tvalidation_1-merror:0.202525\n",
            "[218]\tvalidation_0-merror:0.132702\tvalidation_1-merror:0.202357\n",
            "[219]\tvalidation_0-merror:0.132407\tvalidation_1-merror:0.20202\n",
            "[220]\tvalidation_0-merror:0.132134\tvalidation_1-merror:0.201936\n",
            "[221]\tvalidation_0-merror:0.132029\tvalidation_1-merror:0.201852\n",
            "[222]\tvalidation_0-merror:0.131692\tvalidation_1-merror:0.202273\n",
            "[223]\tvalidation_0-merror:0.131376\tvalidation_1-merror:0.202189\n",
            "[224]\tvalidation_0-merror:0.131334\tvalidation_1-merror:0.20202\n",
            "[225]\tvalidation_0-merror:0.130976\tvalidation_1-merror:0.201852\n",
            "[226]\tvalidation_0-merror:0.131019\tvalidation_1-merror:0.201936\n",
            "[227]\tvalidation_0-merror:0.130724\tvalidation_1-merror:0.201515\n",
            "[228]\tvalidation_0-merror:0.130492\tvalidation_1-merror:0.201178\n",
            "[229]\tvalidation_0-merror:0.130345\tvalidation_1-merror:0.201347\n",
            "[230]\tvalidation_0-merror:0.129945\tvalidation_1-merror:0.201599\n",
            "[231]\tvalidation_0-merror:0.12963\tvalidation_1-merror:0.20101\n",
            "[232]\tvalidation_0-merror:0.129082\tvalidation_1-merror:0.201431\n",
            "[233]\tvalidation_0-merror:0.128577\tvalidation_1-merror:0.201094\n",
            "[234]\tvalidation_0-merror:0.128114\tvalidation_1-merror:0.20101\n",
            "[235]\tvalidation_0-merror:0.127757\tvalidation_1-merror:0.201515\n",
            "[236]\tvalidation_0-merror:0.127483\tvalidation_1-merror:0.20101\n",
            "[237]\tvalidation_0-merror:0.126936\tvalidation_1-merror:0.200758\n",
            "[238]\tvalidation_0-merror:0.126684\tvalidation_1-merror:0.200842\n",
            "[239]\tvalidation_0-merror:0.126473\tvalidation_1-merror:0.200168\n",
            "[240]\tvalidation_0-merror:0.125989\tvalidation_1-merror:0.200421\n",
            "[241]\tvalidation_0-merror:0.125821\tvalidation_1-merror:0.200505\n",
            "[242]\tvalidation_0-merror:0.125337\tvalidation_1-merror:0.200926\n",
            "[243]\tvalidation_0-merror:0.124958\tvalidation_1-merror:0.200673\n",
            "[244]\tvalidation_0-merror:0.124811\tvalidation_1-merror:0.200842\n",
            "[245]\tvalidation_0-merror:0.124537\tvalidation_1-merror:0.200842\n",
            "[246]\tvalidation_0-merror:0.124495\tvalidation_1-merror:0.200673\n",
            "[247]\tvalidation_0-merror:0.124306\tvalidation_1-merror:0.200673\n",
            "[248]\tvalidation_0-merror:0.124116\tvalidation_1-merror:0.200421\n",
            "[249]\tvalidation_0-merror:0.124011\tvalidation_1-merror:0.200842\n",
            "[250]\tvalidation_0-merror:0.12359\tvalidation_1-merror:0.201263\n",
            "[251]\tvalidation_0-merror:0.123527\tvalidation_1-merror:0.201431\n",
            "[252]\tvalidation_0-merror:0.123338\tvalidation_1-merror:0.201431\n",
            "[253]\tvalidation_0-merror:0.12298\tvalidation_1-merror:0.201178\n",
            "[254]\tvalidation_0-merror:0.122559\tvalidation_1-merror:0.20101\n",
            "[255]\tvalidation_0-merror:0.122138\tvalidation_1-merror:0.200673\n",
            "[256]\tvalidation_0-merror:0.12197\tvalidation_1-merror:0.200589\n",
            "[257]\tvalidation_0-merror:0.121822\tvalidation_1-merror:0.200589\n",
            "[258]\tvalidation_0-merror:0.121738\tvalidation_1-merror:0.200589\n",
            "[259]\tvalidation_0-merror:0.12157\tvalidation_1-merror:0.200505\n",
            "[260]\tvalidation_0-merror:0.121402\tvalidation_1-merror:0.200505\n",
            "[261]\tvalidation_0-merror:0.120939\tvalidation_1-merror:0.2\n",
            "[262]\tvalidation_0-merror:0.120623\tvalidation_1-merror:0.2\n",
            "[263]\tvalidation_0-merror:0.120412\tvalidation_1-merror:0.200084\n",
            "[264]\tvalidation_0-merror:0.119928\tvalidation_1-merror:0.200168\n",
            "[265]\tvalidation_0-merror:0.119781\tvalidation_1-merror:0.2\n",
            "[266]\tvalidation_0-merror:0.119487\tvalidation_1-merror:0.199495\n",
            "[267]\tvalidation_0-merror:0.11915\tvalidation_1-merror:0.199663\n",
            "[268]\tvalidation_0-merror:0.118582\tvalidation_1-merror:0.200253\n",
            "[269]\tvalidation_0-merror:0.118455\tvalidation_1-merror:0.200168\n",
            "[270]\tvalidation_0-merror:0.117614\tvalidation_1-merror:0.199411\n",
            "[271]\tvalidation_0-merror:0.117445\tvalidation_1-merror:0.199327\n",
            "[272]\tvalidation_0-merror:0.117066\tvalidation_1-merror:0.199663\n",
            "[273]\tvalidation_0-merror:0.116856\tvalidation_1-merror:0.199327\n",
            "[274]\tvalidation_0-merror:0.116625\tvalidation_1-merror:0.198737\n",
            "[275]\tvalidation_0-merror:0.116393\tvalidation_1-merror:0.198906\n",
            "[276]\tvalidation_0-merror:0.116288\tvalidation_1-merror:0.19899\n",
            "[277]\tvalidation_0-merror:0.115909\tvalidation_1-merror:0.199074\n",
            "[278]\tvalidation_0-merror:0.115804\tvalidation_1-merror:0.199158\n",
            "[279]\tvalidation_0-merror:0.115383\tvalidation_1-merror:0.19899\n",
            "[280]\tvalidation_0-merror:0.115004\tvalidation_1-merror:0.199327\n",
            "[281]\tvalidation_0-merror:0.114689\tvalidation_1-merror:0.19899\n",
            "[282]\tvalidation_0-merror:0.114478\tvalidation_1-merror:0.199074\n",
            "[283]\tvalidation_0-merror:0.114205\tvalidation_1-merror:0.199074\n",
            "[284]\tvalidation_0-merror:0.114141\tvalidation_1-merror:0.199832\n",
            "[285]\tvalidation_0-merror:0.113742\tvalidation_1-merror:0.200084\n",
            "[286]\tvalidation_0-merror:0.113678\tvalidation_1-merror:0.199916\n",
            "[287]\tvalidation_0-merror:0.113468\tvalidation_1-merror:0.199663\n",
            "[288]\tvalidation_0-merror:0.113047\tvalidation_1-merror:0.199327\n",
            "[289]\tvalidation_0-merror:0.113068\tvalidation_1-merror:0.199327\n",
            "[290]\tvalidation_0-merror:0.112774\tvalidation_1-merror:0.199411\n",
            "[291]\tvalidation_0-merror:0.112374\tvalidation_1-merror:0.199074\n",
            "[292]\tvalidation_0-merror:0.112079\tvalidation_1-merror:0.199327\n",
            "[293]\tvalidation_0-merror:0.11189\tvalidation_1-merror:0.19899\n",
            "[294]\tvalidation_0-merror:0.111785\tvalidation_1-merror:0.198737\n",
            "[295]\tvalidation_0-merror:0.111301\tvalidation_1-merror:0.198485\n",
            "[296]\tvalidation_0-merror:0.110838\tvalidation_1-merror:0.199158\n",
            "[297]\tvalidation_0-merror:0.110753\tvalidation_1-merror:0.199579\n",
            "[298]\tvalidation_0-merror:0.110669\tvalidation_1-merror:0.199411\n",
            "[299]\tvalidation_0-merror:0.110501\tvalidation_1-merror:0.199663\n",
            "[300]\tvalidation_0-merror:0.110438\tvalidation_1-merror:0.199495\n",
            "[301]\tvalidation_0-merror:0.110354\tvalidation_1-merror:0.199158\n",
            "[302]\tvalidation_0-merror:0.110185\tvalidation_1-merror:0.198906\n",
            "[303]\tvalidation_0-merror:0.110143\tvalidation_1-merror:0.198906\n",
            "[304]\tvalidation_0-merror:0.109975\tvalidation_1-merror:0.198653\n",
            "[305]\tvalidation_0-merror:0.109659\tvalidation_1-merror:0.198485\n",
            "[306]\tvalidation_0-merror:0.109449\tvalidation_1-merror:0.198737\n",
            "[307]\tvalidation_0-merror:0.108902\tvalidation_1-merror:0.19899\n",
            "[308]\tvalidation_0-merror:0.10867\tvalidation_1-merror:0.198485\n",
            "[309]\tvalidation_0-merror:0.108565\tvalidation_1-merror:0.198569\n",
            "[310]\tvalidation_0-merror:0.108375\tvalidation_1-merror:0.198485\n",
            "[311]\tvalidation_0-merror:0.10787\tvalidation_1-merror:0.198401\n",
            "[312]\tvalidation_0-merror:0.107828\tvalidation_1-merror:0.198316\n",
            "[313]\tvalidation_0-merror:0.107639\tvalidation_1-merror:0.197727\n",
            "[314]\tvalidation_0-merror:0.107597\tvalidation_1-merror:0.197559\n",
            "[315]\tvalidation_0-merror:0.107407\tvalidation_1-merror:0.198064\n",
            "[316]\tvalidation_0-merror:0.107281\tvalidation_1-merror:0.198232\n",
            "[317]\tvalidation_0-merror:0.106965\tvalidation_1-merror:0.198064\n",
            "[318]\tvalidation_0-merror:0.106734\tvalidation_1-merror:0.198316\n",
            "[319]\tvalidation_0-merror:0.106524\tvalidation_1-merror:0.197896\n",
            "[320]\tvalidation_0-merror:0.106229\tvalidation_1-merror:0.197896\n",
            "[321]\tvalidation_0-merror:0.106145\tvalidation_1-merror:0.197391\n",
            "[322]\tvalidation_0-merror:0.105976\tvalidation_1-merror:0.197306\n",
            "[323]\tvalidation_0-merror:0.105787\tvalidation_1-merror:0.197475\n",
            "[324]\tvalidation_0-merror:0.105408\tvalidation_1-merror:0.197559\n",
            "[325]\tvalidation_0-merror:0.105387\tvalidation_1-merror:0.197559\n",
            "[326]\tvalidation_0-merror:0.105219\tvalidation_1-merror:0.197559\n",
            "[327]\tvalidation_0-merror:0.105008\tvalidation_1-merror:0.197896\n",
            "[328]\tvalidation_0-merror:0.10484\tvalidation_1-merror:0.197811\n",
            "[329]\tvalidation_0-merror:0.104714\tvalidation_1-merror:0.198064\n",
            "[330]\tvalidation_0-merror:0.104482\tvalidation_1-merror:0.197896\n",
            "[331]\tvalidation_0-merror:0.104019\tvalidation_1-merror:0.197727\n",
            "[332]\tvalidation_0-merror:0.103914\tvalidation_1-merror:0.197643\n",
            "[333]\tvalidation_0-merror:0.103683\tvalidation_1-merror:0.197727\n",
            "[334]\tvalidation_0-merror:0.103641\tvalidation_1-merror:0.197811\n",
            "[335]\tvalidation_0-merror:0.103367\tvalidation_1-merror:0.197896\n",
            "[336]\tvalidation_0-merror:0.10303\tvalidation_1-merror:0.198148\n",
            "[337]\tvalidation_0-merror:0.102694\tvalidation_1-merror:0.197896\n",
            "[338]\tvalidation_0-merror:0.102673\tvalidation_1-merror:0.197727\n",
            "[339]\tvalidation_0-merror:0.102315\tvalidation_1-merror:0.197811\n",
            "[340]\tvalidation_0-merror:0.102062\tvalidation_1-merror:0.197727\n",
            "[341]\tvalidation_0-merror:0.101957\tvalidation_1-merror:0.197896\n",
            "[342]\tvalidation_0-merror:0.101726\tvalidation_1-merror:0.197811\n",
            "[343]\tvalidation_0-merror:0.101368\tvalidation_1-merror:0.19798\n",
            "[344]\tvalidation_0-merror:0.101221\tvalidation_1-merror:0.197896\n",
            "[345]\tvalidation_0-merror:0.101031\tvalidation_1-merror:0.197727\n",
            "[346]\tvalidation_0-merror:0.100737\tvalidation_1-merror:0.197727\n",
            "[347]\tvalidation_0-merror:0.100568\tvalidation_1-merror:0.197811\n",
            "[348]\tvalidation_0-merror:0.100421\tvalidation_1-merror:0.198064\n",
            "[349]\tvalidation_0-merror:0.100337\tvalidation_1-merror:0.197896\n",
            "[350]\tvalidation_0-merror:0.100147\tvalidation_1-merror:0.197896\n",
            "[351]\tvalidation_0-merror:0.1\tvalidation_1-merror:0.197811\n",
            "[352]\tvalidation_0-merror:0.09979\tvalidation_1-merror:0.197811\n",
            "[353]\tvalidation_0-merror:0.099537\tvalidation_1-merror:0.197727\n",
            "[354]\tvalidation_0-merror:0.099474\tvalidation_1-merror:0.197391\n",
            "[355]\tvalidation_0-merror:0.09939\tvalidation_1-merror:0.197559\n",
            "[356]\tvalidation_0-merror:0.099263\tvalidation_1-merror:0.197643\n",
            "[357]\tvalidation_0-merror:0.099053\tvalidation_1-merror:0.197391\n",
            "[358]\tvalidation_0-merror:0.098611\tvalidation_1-merror:0.197727\n",
            "[359]\tvalidation_0-merror:0.098316\tvalidation_1-merror:0.197222\n",
            "[360]\tvalidation_0-merror:0.098274\tvalidation_1-merror:0.197559\n",
            "[361]\tvalidation_0-merror:0.098148\tvalidation_1-merror:0.197559\n",
            "[362]\tvalidation_0-merror:0.098106\tvalidation_1-merror:0.197391\n",
            "[363]\tvalidation_0-merror:0.097959\tvalidation_1-merror:0.197306\n",
            "[364]\tvalidation_0-merror:0.097811\tvalidation_1-merror:0.197222\n",
            "[365]\tvalidation_0-merror:0.097643\tvalidation_1-merror:0.197727\n",
            "[366]\tvalidation_0-merror:0.097285\tvalidation_1-merror:0.197306\n",
            "[367]\tvalidation_0-merror:0.096949\tvalidation_1-merror:0.197475\n",
            "[368]\tvalidation_0-merror:0.096717\tvalidation_1-merror:0.197306\n",
            "[369]\tvalidation_0-merror:0.096528\tvalidation_1-merror:0.197559\n",
            "[370]\tvalidation_0-merror:0.096254\tvalidation_1-merror:0.19697\n",
            "[371]\tvalidation_0-merror:0.096023\tvalidation_1-merror:0.197138\n",
            "[372]\tvalidation_0-merror:0.09577\tvalidation_1-merror:0.197138\n",
            "[373]\tvalidation_0-merror:0.095602\tvalidation_1-merror:0.197054\n",
            "[374]\tvalidation_0-merror:0.095391\tvalidation_1-merror:0.197222\n",
            "[375]\tvalidation_0-merror:0.095139\tvalidation_1-merror:0.197306\n",
            "[376]\tvalidation_0-merror:0.094718\tvalidation_1-merror:0.197222\n",
            "[377]\tvalidation_0-merror:0.094592\tvalidation_1-merror:0.197306\n",
            "[378]\tvalidation_0-merror:0.094381\tvalidation_1-merror:0.19697\n",
            "[379]\tvalidation_0-merror:0.094381\tvalidation_1-merror:0.197054\n",
            "[380]\tvalidation_0-merror:0.094066\tvalidation_1-merror:0.197391\n",
            "[381]\tvalidation_0-merror:0.094045\tvalidation_1-merror:0.197391\n",
            "[382]\tvalidation_0-merror:0.093918\tvalidation_1-merror:0.197222\n",
            "[383]\tvalidation_0-merror:0.093855\tvalidation_1-merror:0.197222\n",
            "[384]\tvalidation_0-merror:0.093792\tvalidation_1-merror:0.19697\n",
            "[385]\tvalidation_0-merror:0.093687\tvalidation_1-merror:0.197475\n",
            "[386]\tvalidation_0-merror:0.093455\tvalidation_1-merror:0.197643\n",
            "[387]\tvalidation_0-merror:0.093287\tvalidation_1-merror:0.197811\n",
            "[388]\tvalidation_0-merror:0.093203\tvalidation_1-merror:0.197643\n",
            "[389]\tvalidation_0-merror:0.093098\tvalidation_1-merror:0.197727\n",
            "[390]\tvalidation_0-merror:0.092887\tvalidation_1-merror:0.197896\n",
            "[391]\tvalidation_0-merror:0.092656\tvalidation_1-merror:0.197811\n",
            "[392]\tvalidation_0-merror:0.092361\tvalidation_1-merror:0.197811\n",
            "[393]\tvalidation_0-merror:0.091982\tvalidation_1-merror:0.197306\n",
            "[394]\tvalidation_0-merror:0.091814\tvalidation_1-merror:0.197559\n",
            "[395]\tvalidation_0-merror:0.091625\tvalidation_1-merror:0.197391\n",
            "[396]\tvalidation_0-merror:0.091435\tvalidation_1-merror:0.197559\n",
            "[397]\tvalidation_0-merror:0.091372\tvalidation_1-merror:0.197643\n",
            "[398]\tvalidation_0-merror:0.091098\tvalidation_1-merror:0.197727\n",
            "[399]\tvalidation_0-merror:0.090972\tvalidation_1-merror:0.197643\n",
            "[400]\tvalidation_0-merror:0.090741\tvalidation_1-merror:0.197896\n",
            "[401]\tvalidation_0-merror:0.090446\tvalidation_1-merror:0.19798\n",
            "[402]\tvalidation_0-merror:0.090194\tvalidation_1-merror:0.19798\n",
            "[403]\tvalidation_0-merror:0.090173\tvalidation_1-merror:0.198401\n",
            "[404]\tvalidation_0-merror:0.089878\tvalidation_1-merror:0.198148\n",
            "[405]\tvalidation_0-merror:0.089541\tvalidation_1-merror:0.197811\n",
            "[406]\tvalidation_0-merror:0.089268\tvalidation_1-merror:0.197811\n",
            "[407]\tvalidation_0-merror:0.089057\tvalidation_1-merror:0.197896\n",
            "[408]\tvalidation_0-merror:0.088889\tvalidation_1-merror:0.198064\n",
            "[409]\tvalidation_0-merror:0.089015\tvalidation_1-merror:0.197811\n",
            "[410]\tvalidation_0-merror:0.088868\tvalidation_1-merror:0.197896\n",
            "[411]\tvalidation_0-merror:0.088742\tvalidation_1-merror:0.197727\n",
            "[412]\tvalidation_0-merror:0.088384\tvalidation_1-merror:0.19798\n",
            "[413]\tvalidation_0-merror:0.0883\tvalidation_1-merror:0.198064\n",
            "[414]\tvalidation_0-merror:0.08811\tvalidation_1-merror:0.197811\n",
            "[415]\tvalidation_0-merror:0.088026\tvalidation_1-merror:0.19798\n",
            "[416]\tvalidation_0-merror:0.087837\tvalidation_1-merror:0.197727\n",
            "[417]\tvalidation_0-merror:0.087816\tvalidation_1-merror:0.197727\n",
            "[418]\tvalidation_0-merror:0.087753\tvalidation_1-merror:0.197643\n",
            "[419]\tvalidation_0-merror:0.087584\tvalidation_1-merror:0.197811\n",
            "[420]\tvalidation_0-merror:0.087184\tvalidation_1-merror:0.198064\n",
            "Stopping. Best iteration:\n",
            "[370]\tvalidation_0-merror:0.096254\tvalidation_1-merror:0.19697\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=7,\n",
              "              min_child_weight=1, missing=None, n_estimators=1000, n_jobs=-1,\n",
              "              nthread=None, objective='multi:softprob', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KoXB3nZUvCg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "db3123ff-1c77-4e32-d9b7-2020e023ff1e"
      },
      "source": [
        "model.evals_result()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'validation_0': {'merror': [0.250821,\n",
              "   0.235774,\n",
              "   0.233838,\n",
              "   0.225105,\n",
              "   0.21814,\n",
              "   0.210164,\n",
              "   0.205598,\n",
              "   0.201599,\n",
              "   0.19798,\n",
              "   0.195265,\n",
              "   0.191898,\n",
              "   0.189878,\n",
              "   0.186595,\n",
              "   0.184133,\n",
              "   0.181082,\n",
              "   0.178367,\n",
              "   0.176452,\n",
              "   0.173822,\n",
              "   0.171928,\n",
              "   0.17016,\n",
              "   0.168308,\n",
              "   0.164962,\n",
              "   0.1633,\n",
              "   0.161279,\n",
              "   0.160038,\n",
              "   0.157891,\n",
              "   0.15686,\n",
              "   0.155913,\n",
              "   0.154419,\n",
              "   0.15141,\n",
              "   0.1496,\n",
              "   0.148106,\n",
              "   0.146023,\n",
              "   0.144971,\n",
              "   0.144339,\n",
              "   0.143161,\n",
              "   0.141877,\n",
              "   0.139731,\n",
              "   0.1367,\n",
              "   0.135838,\n",
              "   0.134428,\n",
              "   0.133838,\n",
              "   0.131608,\n",
              "   0.129756,\n",
              "   0.128283,\n",
              "   0.126136,\n",
              "   0.124116,\n",
              "   0.122012,\n",
              "   0.121549,\n",
              "   0.120812,\n",
              "   0.118897,\n",
              "   0.117908,\n",
              "   0.116162,\n",
              "   0.115278,\n",
              "   0.114099,\n",
              "   0.112647,\n",
              "   0.111406,\n",
              "   0.110627,\n",
              "   0.10928,\n",
              "   0.108018,\n",
              "   0.106755,\n",
              "   0.10564,\n",
              "   0.102946,\n",
              "   0.102378,\n",
              "   0.101178,\n",
              "   0.100421,\n",
              "   0.098885,\n",
              "   0.097685,\n",
              "   0.097117,\n",
              "   0.096843,\n",
              "   0.095707,\n",
              "   0.094697,\n",
              "   0.093434,\n",
              "   0.092382,\n",
              "   0.091709,\n",
              "   0.090657,\n",
              "   0.089415,\n",
              "   0.088173,\n",
              "   0.087269,\n",
              "   0.086343,\n",
              "   0.085354,\n",
              "   0.084407,\n",
              "   0.08306,\n",
              "   0.082681,\n",
              "   0.082218,\n",
              "   0.080703,\n",
              "   0.079503,\n",
              "   0.078346,\n",
              "   0.076747,\n",
              "   0.075442,\n",
              "   0.075231,\n",
              "   0.074306,\n",
              "   0.073611,\n",
              "   0.073064,\n",
              "   0.072769,\n",
              "   0.071949,\n",
              "   0.071107,\n",
              "   0.070812,\n",
              "   0.070434,\n",
              "   0.069907,\n",
              "   0.068582,\n",
              "   0.067887,\n",
              "   0.066961,\n",
              "   0.066014,\n",
              "   0.065572,\n",
              "   0.06452,\n",
              "   0.063594,\n",
              "   0.06311,\n",
              "   0.061911,\n",
              "   0.06109,\n",
              "   0.060417,\n",
              "   0.059701,\n",
              "   0.058944,\n",
              "   0.057765,\n",
              "   0.056797,\n",
              "   0.056334,\n",
              "   0.055619,\n",
              "   0.054861,\n",
              "   0.054335,\n",
              "   0.05383,\n",
              "   0.053157,\n",
              "   0.052567,\n",
              "   0.052146,\n",
              "   0.051347,\n",
              "   0.050968,\n",
              "   0.050694,\n",
              "   0.050337,\n",
              "   0.049916,\n",
              "   0.049285,\n",
              "   0.048611,\n",
              "   0.047643,\n",
              "   0.047096,\n",
              "   0.046359,\n",
              "   0.045833,\n",
              "   0.045076,\n",
              "   0.044318,\n",
              "   0.043897,\n",
              "   0.043013,\n",
              "   0.042256,\n",
              "   0.041877,\n",
              "   0.041393,\n",
              "   0.041035,\n",
              "   0.040678,\n",
              "   0.040425,\n",
              "   0.040067,\n",
              "   0.039268,\n",
              "   0.038847,\n",
              "   0.038384,\n",
              "   0.037942,\n",
              "   0.03771,\n",
              "   0.037332,\n",
              "   0.036553,\n",
              "   0.036153,\n",
              "   0.035922,\n",
              "   0.035522,\n",
              "   0.035164,\n",
              "   0.035101,\n",
              "   0.03468,\n",
              "   0.03428,\n",
              "   0.034112,\n",
              "   0.033796,\n",
              "   0.033418,\n",
              "   0.032618,\n",
              "   0.032281,\n",
              "   0.031566,\n",
              "   0.031418,\n",
              "   0.031166,\n",
              "   0.030913,\n",
              "   0.030766,\n",
              "   0.030429,\n",
              "   0.030135,\n",
              "   0.029419,\n",
              "   0.029019,\n",
              "   0.028662,\n",
              "   0.028577,\n",
              "   0.028451,\n",
              "   0.028136,\n",
              "   0.027462,\n",
              "   0.027378,\n",
              "   0.027273,\n",
              "   0.026747,\n",
              "   0.026431,\n",
              "   0.026178,\n",
              "   0.025631,\n",
              "   0.025295,\n",
              "   0.024684,\n",
              "   0.024579,\n",
              "   0.024053,\n",
              "   0.023464,\n",
              "   0.022854,\n",
              "   0.022601,\n",
              "   0.022475]},\n",
              " 'validation_1': {'merror': [0.261027,\n",
              "   0.246549,\n",
              "   0.244865,\n",
              "   0.239141,\n",
              "   0.233923,\n",
              "   0.230303,\n",
              "   0.226178,\n",
              "   0.223232,\n",
              "   0.221465,\n",
              "   0.220875,\n",
              "   0.21633,\n",
              "   0.215909,\n",
              "   0.213721,\n",
              "   0.212626,\n",
              "   0.211785,\n",
              "   0.211448,\n",
              "   0.210606,\n",
              "   0.209512,\n",
              "   0.20968,\n",
              "   0.208586,\n",
              "   0.209091,\n",
              "   0.207744,\n",
              "   0.208249,\n",
              "   0.207828,\n",
              "   0.207239,\n",
              "   0.20665,\n",
              "   0.206313,\n",
              "   0.206313,\n",
              "   0.206061,\n",
              "   0.204882,\n",
              "   0.204798,\n",
              "   0.204377,\n",
              "   0.203704,\n",
              "   0.20404,\n",
              "   0.203956,\n",
              "   0.203367,\n",
              "   0.202778,\n",
              "   0.202525,\n",
              "   0.202441,\n",
              "   0.201852,\n",
              "   0.20202,\n",
              "   0.202189,\n",
              "   0.202609,\n",
              "   0.203283,\n",
              "   0.205135,\n",
              "   0.203199,\n",
              "   0.202525,\n",
              "   0.202946,\n",
              "   0.202694,\n",
              "   0.20362,\n",
              "   0.202609,\n",
              "   0.203367,\n",
              "   0.204461,\n",
              "   0.20404,\n",
              "   0.203872,\n",
              "   0.203872,\n",
              "   0.204882,\n",
              "   0.204966,\n",
              "   0.205387,\n",
              "   0.205387,\n",
              "   0.206313,\n",
              "   0.205724,\n",
              "   0.204377,\n",
              "   0.204882,\n",
              "   0.204798,\n",
              "   0.204461,\n",
              "   0.204125,\n",
              "   0.203535,\n",
              "   0.201936,\n",
              "   0.201515,\n",
              "   0.202104,\n",
              "   0.202609,\n",
              "   0.203114,\n",
              "   0.20303,\n",
              "   0.203199,\n",
              "   0.203367,\n",
              "   0.203199,\n",
              "   0.20303,\n",
              "   0.202946,\n",
              "   0.202946,\n",
              "   0.20404,\n",
              "   0.203283,\n",
              "   0.203872,\n",
              "   0.203704,\n",
              "   0.203788,\n",
              "   0.20303,\n",
              "   0.203114,\n",
              "   0.20362,\n",
              "   0.203367,\n",
              "   0.203114,\n",
              "   0.20303,\n",
              "   0.201684,\n",
              "   0.201431,\n",
              "   0.201599,\n",
              "   0.201431,\n",
              "   0.200673,\n",
              "   0.200842,\n",
              "   0.200673,\n",
              "   0.200421,\n",
              "   0.200337,\n",
              "   0.200673,\n",
              "   0.200758,\n",
              "   0.201094,\n",
              "   0.201768,\n",
              "   0.201599,\n",
              "   0.200842,\n",
              "   0.200505,\n",
              "   0.2,\n",
              "   0.2,\n",
              "   0.199411,\n",
              "   0.199242,\n",
              "   0.199158,\n",
              "   0.199663,\n",
              "   0.199832,\n",
              "   0.199916,\n",
              "   0.199663,\n",
              "   0.200253,\n",
              "   0.200337,\n",
              "   0.200673,\n",
              "   0.200589,\n",
              "   0.200084,\n",
              "   0.200421,\n",
              "   0.199832,\n",
              "   0.199832,\n",
              "   0.199916,\n",
              "   0.200589,\n",
              "   0.199916,\n",
              "   0.200337,\n",
              "   0.2,\n",
              "   0.200505,\n",
              "   0.201094,\n",
              "   0.200842,\n",
              "   0.200421,\n",
              "   0.200084,\n",
              "   0.200337,\n",
              "   0.200421,\n",
              "   0.200168,\n",
              "   0.199158,\n",
              "   0.199242,\n",
              "   0.199158,\n",
              "   0.19899,\n",
              "   0.198737,\n",
              "   0.198232,\n",
              "   0.198906,\n",
              "   0.199242,\n",
              "   0.199158,\n",
              "   0.200168,\n",
              "   0.200337,\n",
              "   0.200505,\n",
              "   0.200673,\n",
              "   0.200421,\n",
              "   0.199411,\n",
              "   0.199579,\n",
              "   0.199495,\n",
              "   0.198906,\n",
              "   0.199832,\n",
              "   0.200253,\n",
              "   0.201431,\n",
              "   0.200421,\n",
              "   0.200337,\n",
              "   0.2,\n",
              "   0.2,\n",
              "   0.199916,\n",
              "   0.200084,\n",
              "   0.200337,\n",
              "   0.200589,\n",
              "   0.200337,\n",
              "   0.200589,\n",
              "   0.200421,\n",
              "   0.20101,\n",
              "   0.20101,\n",
              "   0.200337,\n",
              "   0.201515,\n",
              "   0.20101,\n",
              "   0.200926,\n",
              "   0.200842,\n",
              "   0.201178,\n",
              "   0.201599,\n",
              "   0.202104,\n",
              "   0.201768,\n",
              "   0.201515,\n",
              "   0.200842,\n",
              "   0.201178,\n",
              "   0.201599,\n",
              "   0.201347,\n",
              "   0.201515,\n",
              "   0.201347,\n",
              "   0.201515,\n",
              "   0.201768,\n",
              "   0.200842,\n",
              "   0.201263,\n",
              "   0.20101]}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hctOmlOfVrJd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "f3de85ff-6653-4a18-d74e-6cef926e2b6b"
      },
      "source": [
        "results = model.evals_result()\n",
        "train_error = results['validation_0']['merror']\n",
        "val_error = results['validation_1']['merror']\n",
        "epoch = range(1, len(train_error)+1)\n",
        "plt.plot(epoch, train_error, label='Train')\n",
        "plt.plot(epoch, val_error, label='Validation')\n",
        "plt.ylabel('Classification Error')\n",
        "plt.xlabel('Model Complexity (n_estimators)')\n",
        "plt.legend();\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAELCAYAAAAhuwopAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF7-ml6BhRRf",
        "colab_type": "text"
      },
      "source": [
        "## Try adjusting these hyperparameters\n",
        "\n",
        "#### Random Forest\n",
        "- class_weight (for imbalanced classes)\n",
        "- max_depth (usually high, can try decreasing)\n",
        "- n_estimators (too low underfits, too high wastes time)\n",
        "- min_samples_leaf (increase if overfitting)\n",
        "- max_features (decrease for more diverse trees)\n",
        "\n",
        "#### Xgboost\n",
        "- scale_pos_weight (for imbalanced classes)\n",
        "- max_depth (usually low, can try increasing)\n",
        "- n_estimators (too low underfits, too high wastes time/overfits) — Use Early Stopping!\n",
        "- learning_rate (too low underfits, too high overfits)\n",
        "\n",
        "For more ideas, see [Notes on Parameter Tuning](https://xgboost.readthedocs.io/en/latest/tutorials/param_tuning.html) and [DART booster](https://xgboost.readthedocs.io/en/latest/tutorials/dart.html)."
      ]
    }
  ]
}